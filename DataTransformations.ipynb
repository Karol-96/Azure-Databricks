{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Map() : The map() transformation is used to apply a function to each element in an RDD. It is typically used to perform operations on each element.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4])\n",
    "mapped_rdd = rdd.map(lambda x: x * 2)\n",
    "mapped_rdd.collect()  # Output: [2, 4, 6, 8]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Filter(): The filter() transformation allows you to filter out elements that do not meet a specified condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
    "filtered_rdd = rdd.filter(lambda x: x % 2 == 0)\n",
    "filtered_rdd.collect()  # Output: [2, 4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Groupby() : The groupBy() transformation groups the elements of an RDD based on the specified key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([(\"apple\", 1), (\"orange\", 2), (\"apple\", 3), (\"orange\", 4)])\n",
    "grouped_rdd = rdd.groupBy(lambda x: x[0])\n",
    "grouped_rdd.collect()  # Output: [('apple', <pyspark.resultiterable.ResultIterable at ...>), ('orange', <pyspark.resultiterable.ResultIterable at ...>)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Join() :  The join() transformation is used to join two RDDs based on a key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "rdd1 = sc.parallelize([(\"a\", 1), (\"b\", 2), (\"c\", 3)])\n",
    "rdd2 = sc.parallelize([(\"a\", \"apple\"), (\"b\", \"banana\"), (\"d\", \"date\")])\n",
    "joined_rdd = rdd1.join(rdd2)\n",
    "joined_rdd.collect()  # Output: [('a', (1, 'apple')), ('b', (2, 'banana'))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Repartition : It is used to increase or decrease number of partition in RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize((1,2,3,4,5),2)\n",
    "repartitioned_rdd = rdd.repartition(4)\n",
    "print(repartitioned_rdd.getNumPartitions())  # Output: 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. FlatMap() : It is similar to map but allows you to return multiple value for each input element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3])\n",
    "flat_mapped_rdd = rdd.flatMap(lambda x: (x, x + 1))\n",
    "flat_mapped_rdd.collect()  # Output: [1, 2, 2, 3, 3, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Distinct : The distinct() transformation is used to remove duplicate elements from an RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 2, 3, 4, 4])\n",
    "distinct_rdd = rdd.distinct()\n",
    "distinct_rdd.collect()  # Output: [1, 2, 3, 4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. ReduceByKey() : The reduceByKey() transformation is used to merge the values for each key using an associative and commutative reduce function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([(\"a\", 1), (\"b\", 2), (\"a\", 3), (\"b\", 4)])\n",
    "reduced_rdd = rdd.reduceByKey(lambda x, y: x + y)\n",
    "reduced_rdd.collect()  # Output: [('a', 4), ('b', 6)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Sample() : The sample() transformation is used to sample a subset of the RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4, 5, 6])\n",
    "sampled_rdd = rdd.sample(False, 0.5)\n",
    "sampled_rdd.collect()  # Output: [1, 3, 5] (output may vary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Cartesian() : The cartesian() transformation returns the Cartesian product of two RDDs, meaning every possible pair of elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "rdd1 = sc.parallelize([1, 2])\n",
    "rdd2 = sc.parallelize([3, 4])\n",
    "cartesian_rdd = rdd1.cartesian(rdd2)\n",
    "cartesian_rdd.collect()  # Output: [(1, 3), (1, 4), (2, 3), (2, 4)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
